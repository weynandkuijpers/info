+++

#Don't remove name!
title = "What can I do with the New Edge Cloud"
image = "../img/what-can-i-do.jpg"
author = "Weynand Kujipers"
subtitle = "Some description of use cases of how the ThreeFold Edge Cloud can be used."
weight = 7

+++

## Any Docker Service
The TF-node runs containers natively - therefore it can run any Docker service.  But it does so a lot more efficient than the Docker engine, the most used and known container technology platforms.

### IAAS

The TF-node technology enables hardware capabilities to be used for IAAS services in a very efficient way.  Overhead is reduced to a minimum by stripping out unnecessary layers of software that have been invented and implemented over the last decade to patch scaling and performance problems.  The engineers have always looked at the root cause of issues and by innovating at the core algorithm level solved issues. Examples are:

- **Less is more**: Scale down the operating system for a virtualisation architecture to a minimum and boot it over the network - no local operating system files installed on local storage.
- **Look at root causes, do not invent painkillers**: Step away from existing storage solutions that have a need for proprietary acceleration hardware and use standard off the shelf, affordable and efficient components with a 100% software based storage solution that is able to withstand hardware failures without requiring human intervention - creating a very efficient, reliable and performing storage solution that can operate standalone.

The platform is secure by using a network boot mechanism making it virtually hack resistant because there are no operating system files installed locally.
Infrastructure as a service traditionally runs in hyperscale datacenters remote from the businesses using it. TF-node technology allows you to install, operate and run IAAS services close to your business locations operated by your local IT team.  It operates on a peer2peer network only transferring bits of data that need to be transported avoiding network congestion and traffic bottlenecks.

### Archive
Data generation is growing exponentially. More data has been generated in the last 2 years than ever before. This data needs to be archived. The TF-node technology creates storage and archiving capabilities by using standard hardware and known interfaces will be build by developers wordwide and made available (S3, FTP, WebDav, CIFS and NFS).  The low levels storage functionality supports version controlling of the archived data which keeps all relevant changes without any limitation by using a small amount of actual storage capacity.  

Data security and reliability are key aspects of any storage system.  The TF-node allows all data to be compressed and encrypted if and when needed. The distributed character of the storage system enables site redundant storage algorithms to be deployed keeping large data volumes from being stored in a single location taking away the risk of data being stolen (physically) and that of a site outage leading to a data outage.  The distributed character of the system is inline with the increasing spread of actual data generation.  We have sensory equipment everywhere these days and the overhead of storing all that information in a few central places is enormous  Data collection and storage happens once - reading data to use it for a particular workload happens many times.

### Data Mining
On traditional server architectures, every application has to set up its own servers that run their own code in isolated silos, making sharing of data hard. The distributed character of the TF-node technology presents compute and storage capacity everywhere.  This enables large data mining workloads to happen close to the source of the data.  Data is stored in a distributed manner and therefore data mining can happen in a distributed manner as well. Distributed compute capacity next to storage capabilities creates the possibility to create data mining operations on local storage (which makes it very fast and efficient) by coding data mining algorithms in programming languages like python, lua, javascript and golang. Data mining follows distributed data storage.

Never run into scalability problems again - the TF-node data store can expand horizontally using thousands of distributed nodes to create large storage volumes.

### Smart Contracts

Smart contracts are applications that run on a decentralised platform, exactly as programmed without any possibility of downtime, censorship, fraud or third party interference . These apps run on a blockchain, an enormously powerful shared global infrastructure that can move value around and represent the ownership of property. Smart contracts enable developers to create markets, store registries of debts (or promises), move funds in accordance with instructions given long in the past (like a will or a futures contract) and many other things without a middleman or counterparty risk.  TF-nodes run. 


The TF-node technology natively supports the existing Ethereum network  and will have it's own way of running smart contracts by deploying a new blockchain technology, presenting a whole new approach on how to run  blockchain.

### Self Learning & AI
Blockchains can be seen as databases. By current database standards, traditional blockchains like Bitcoin are terrible: low throughput, low capacity, high latency, poor query support, and so on. But even with these terrible characteristics blockchains introduce three new and important characteristics:

- Decentralized data and shared data control.  Very simply said this leads to more data and qualitative better data which result in better models. Shortening the machine learning time and get AI progressing in a much faster pace.  
- Immutable audit trails improve the trustworthiness of the data & models increasing provenance on training and testing results.
- Native assets and  assets exchanges make  training and testing models intellectual property (IP) assets, which enhancing decentralized data & model exchanges.

Blockchain technology allows more data and with better quality to be presented to machine learning algorithms.  It has been proven (Microsoft researchers Banko and Brill) that more data — not just a bit more data but orders of magnitude more data — while  using same algorithms results in a lot better machine learning.  Meaning that the future of machine learning is not in trying to create more sophisticated algorithms (which will happen) .  So by moving AI learning into a blockchain environment we speed up machine learning and in the end create AI.
