+++
# Don't remove name!
title = "Datacenter Myths"
image = "../img/myth-big-datacenters-are-efficient.jpg"
author = "Andreas Hartl"
subtitle = "Hyperscale realities"
weight = 4

+++

### Myth 1: big data centers are more efficient than small ones.

There are advantages in building large scale data centers like economies of scale and shear bulk buying power compared to small ones but these are not as big as people think. The average cost per rack in a hyper scale data center is 20-35K USD including all energy, safety systems. The cost of the hardware per rack is around the 200-300k USD mark.

What is often forgotten is that anything that is of enormous scale and therefore highly concentrated are complex and have a specific set of problems to deal with. Think of resource requirements like investment, operational costs, knowledge and people.

In reality keeping things simple, small is much more cost effective than a big complex environment.

### Myth 2: big data center can be made green.

The carbon footprint of a big datacenter is enormous. To improve the PUE (Power Usage Effectiveness) most data center farmers have adopted windy, hydro and/or solar power technologies, which indeed does help drop their PUE by an estimated 20%.

While this 20% looks great on paper and in the farmers' corporate social responsibility reports. It is mostly just an improvement on the cooling technology, not the actual energy power consumed by the equipment that runs in their data centers (servers, storage chassis', physical disks, etc) and this equipment is what makes up the 100% of the carbon footprint. While the PUE only speaks about overhead power consumption to cool the facility, open and close doors, power security systems, etc.

So the real improvement lies in deploying technologies that actually consume less power to deliver the actual Internet IT capacity to run the workloads, real CPU chassis, physical disks and storage cabinets. Working on how hardware is being more effectively used can have an impact of 1000% and lead to 10 times more power efficiency.

### Myth 3: redundant systems have a better uptime?

This is how a lot of us have been raised. Systems need redundancy mechanisms to improve their operational uptime and reliability. And to be honest if you look at it (through IT tainted glasses) for a minutes this seems to make a lot of sense…. But what if we translate this to the non IT World:

To make a car more reliable we add redundancy (as we do in IT). So for the risk of having a puncture we add one extra tire for all the tires we use continuously. This adds 4 extra tires to the car. Then a decision needs to be made: Do we put those tires in a structure where they are always running along the primary tires or do we chose not to have them "on line" all the time and wearing and tearing as the primary tires?

To build such a system which that would change cars as we know them, and it would take a large number of engineers come up with a solution. And while they will come up with a solution, would it not make more sense to think outside the box and solve the root of the problem by making tires undeflatable?

The IT industry has gone overboard  with the concept of redundancy, it forgot somehow to look  at root causes which helped spawning a whole new industry of itself, that obviously want to keep themselves in the business of creating complicated and expensive redundant system.

### Myth 4: big companies know better how to optimize.

'''Big companies with a certain track record will know better how to optimize, they have more people…'''

At first sight this sounds logical but still if we look at the IT landscape today 90%+ of innovation in IT is done by small startups. The big legacy IT companies have a huge heritage they hardly can overcome. They are locked in old infrastructure designs and after a while the build out of the infrastructure becomes the brake for their business. Real innovation dies a slows death and in comes the pain killer approach.
